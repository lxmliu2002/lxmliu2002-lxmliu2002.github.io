<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem | lxmliu2002's blog</title><meta name="author" content="Xiuming Liu"><meta name="copyright" content="Xiuming Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="ffffff"><meta name="description" content="PaperReading">
<meta property="og:type" content="article">
<meta property="og:title" content="PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem">
<meta property="og:url" content="http://example.com/2024/03/25/PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem/index.html">
<meta property="og:site_name" content="lxmliu2002&#39;s blog">
<meta property="og:description" content="PaperReading">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg">
<meta property="article:published_time" content="2024-03-24T16:00:00.000Z">
<meta property="article:modified_time" content="2024-03-25T14:59:21.827Z">
<meta property="article:author" content="Xiuming Liu">
<meta property="article:tag" content="Binary-Code-Search">
<meta property="article:tag" content="Vulnerability-Search">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg"><link rel="shortcut icon" href="https://github.com/lxmliu2002/images/raw/main/favicon.ico"><link rel="canonical" href="http://example.com/2024/03/25/PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: {"defaultEncoding":1,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: true,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-03-25 22:59:21'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', 'ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<link rel="stylesheet" href="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.css" /><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://github.com/lxmliu2002/images/raw/main/lxmliu2002.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 文档</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image: url('https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="lxmliu2002's blog"><span class="site-name">lxmliu2002's blog</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 文档</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-03-24T16:00:00.000Z" title="发表于 2024-03-25 00:00:00">2024-03-25</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-03-25T14:59:21.827Z" title="更新于 2024-03-25 22:59:21">2024-03-25</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Binary-Code-Search/">Binary-Code-Search</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Vulnerability-Search/">Vulnerability-Search</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="How-Machine-Learning-Is-Solving-the-Binary-Function-Similarity-Problem"><a href="#How-Machine-Learning-Is-Solving-the-Binary-Function-Similarity-Problem" class="headerlink" title="How Machine Learning Is Solving the Binary Function Similarity Problem"></a>How Machine Learning Is Solving the Binary Function Similarity Problem</h1><h2 id="通读"><a href="#通读" class="headerlink" title="通读"></a>通读</h2><h3 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h3><p>精确计算两段二进制代码之间的相似度的能力在许多不同的问题中起着重要的作用。本文对该领域的最新技术进行评估研究。首先将其系统化，确定了代表三个不同社区新提出的解决方案。本文重新实现这些方案并使用不同编译器、优化选项和三种不同编译架构创建了一个新数据集。以此系统评估二进制相似度方法。</p>
<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>二元函数相似度是指将一对函数的二进制表示作为输入，生成一个数值表示二者间的相似性。但是，不同的编译工具链、优化选项等，会使得简单的判定方法失效。</p>
<h4 id="Challenges"><a href="#Challenges" class="headerlink" title="Challenges"></a>Challenges</h4><p><strong>第一个挑战</strong>是目前既不能重现也不能复制以前的结果。由于重新实现以前的技术非常复杂且非常耗时，因此每个解决方案通常只与以前的几个技术进行比较，这些技术有时甚至不是为了解决相同的问题而设计的，并且在某些极端情况下，只与同一作者的先前论文进行比较。</p>
<p><strong>第二个挑战</strong>是评估结果往往是不透明的。不同的解决方案通常是针对略有不同的目标（搜索漏洞 vs. 发现类似的恶意软件样本)，在不同的设置（交叉编译器 vs. 交叉架构)，通过使用不同的相似性概念（相同的代码 vs. 相同的语义)，并在不同的粒度（代码片段 vs. 整个函数)操作。实验也在不同大小和性质的数据集上进行（firmware vs. 命令行实用程序)，并通过使用不同的指标（ROC 曲线 vs. top-n vs. MRR10)报告结果。因此每篇论文中的数值都无法直接比较。而且，不同的论文并不指明特定情景，且不说明其过滤掉细节、如何进行训练等，使得其难以再现。</p>
<p>不同的环境的可靠性实际上是如何影响性能是不得知的，即不清楚给定方法的优越结果是否与一些新的贡献有关。这两个挑战的综合影响导致形成了一个极其碎片化的领域，存在数十种技术，但没有明确了解哪种技术在哪种环境下有效（或无效）。这给我们带来了<strong>最后一个挑战</strong>：很难理解二进制相似性研究的方向。每个新的解决方案都采用了一种更复杂的技术，或者是多种技术的新组合，很难判断这是由更简单方法的实际限制驱动的，还是由需要说服审稿人相信每个工作的新颖性驱动的。这种碎片化通常会导致平行和不相交的研究方向，每个人都声称具有最佳的解决方案。这种碎片化也导致了评估和方法次优的论文。</p>
<h4 id="Contributions"><a href="#Contributions" class="headerlink" title="Contributions"></a>Contributions</h4><p>本文对该研究领域进行了一个系统评估。首先探索现有的研究，并根据所采用的方法对每个解决方案进行分组，特别关注最近基于机器学习的成功技术。然后选择、比较和实现十种最具代表性的方法及其可能的变体。这些方法代表了广泛的趋势，跨越了三个不同的研究社区：计算机安全，编程语言分析，以及机器学习社区。为了使得比较有意义，本文对实现建立在一个共同的框架之上。并利用并行编程和高效的编码技术避免对模型性能产生负面瓶颈。</p>
<p>通过重新实现各种方法（不一定是“论文”），本文分离出现有的“原语”，并在单独使用或相互结合使用时对它们进行评估，以获得见解并确定隐藏在先前作品复杂性中的重要因素，并回答各种开放的研究问题。为了使评估工作更具可比性，本文还提出了一个新的数据集，作为不同方面（如编译器系列、优化和体系结构)的通用基准。</p>
<blockquote>
<p>本文侧重于评估迄今为止提出的主要技术，而非重现论文报告中的准确数据。</p>
</blockquote>
<p>本文还发现了几个有趣的见解。例如，我们发现，虽然简单的方法（例如，模糊散列）在简单的设置中工作得很好，但在处理更复杂的场景时（例如跨架构数据集，或多个变量同时变化的数据集），它们就失败了。在机器学习模型中，基于图神经网络的模型在几乎所有任务中都取得了最好的结果，并且在比较推理时间时是最快的。另一个有趣的发现是，许多最近发表的论文在同一数据集上进行测试时都具有非常相似的准确性，尽管有几篇论文声称在技术水平上有所改进。</p>
<p>虽然我们不声称我们的代码或数据集比以前的作品更好或更有代表性，但我们发布了我们的模块化框架，重新实现了所有选定的方法，完整的数据集，以及如何重新创建和调整它的详细说明通过允许社区对单个组件进行实验并直接相互比较，我们希望鼓励和减轻未来对接近这一活跃研究领域感兴趣的研究人员的努力。</p>
<h3 id="The-Binary-Function-Similarity-Problem"><a href="#The-Binary-Function-Similarity-Problem" class="headerlink" title="The Binary Function Similarity Problem"></a>The Binary Function Similarity Problem</h3><p>在其最简单的形式中，二进制函数相似性旨在计算一个数值，该数值捕获一对函数在其二进制表示中的“相似性”，即由编译器生成的构成函数体的原始字节（即机器代码)。请注意，在本文中，我们关注的是使用函数作为代码单元的方法，研究人员也研究了专注于低级抽象（例如，基本块)或高级抽象（例如，整个程序)的技术。根据我们的定义，两个“相似”函数可能具有截然不同的二进制表示——这就是这使得这个研究问题变得有趣且具有挑战性的原因。</p>
<p>二进制函数相似度已经在一百多篇论文中得到了研究。使情况更加复杂的是，大多数现有的方法不能映射到单一的技术类别，因为它们通常构建在不同的组件之上。在此，专注于这些方法组合的不同构建块，首先查看计算相似性的技术，然后查看这些方法可以利用的输入数据类型。</p>
<h4 id="Measuring-Function-Similarity"><a href="#Measuring-Function-Similarity" class="headerlink" title="Measuring Function Similarity"></a>Measuring Function Similarity</h4><h5 id="Direct-vs-indirect-comparison"><a href="#Direct-vs-indirect-comparison" class="headerlink" title="Direct vs. indirect comparison"></a>Direct vs. indirect comparison</h5><p>我们可以将测量函数相似性的技术分为两大类。<strong>第一类解决方案</strong>通过考虑原始输入数据或实现某种特征提取来实现函数对的直接比较。这些解决方案通常需要了解两个看似不相关的值可以表示相似的函数，反之亦然，接近的值不一定表示相似的东西。当从二进制函数中提取的特征不能通过使用基本相似性度量直接进行比较时，就会出现这种情况，因为它们可能没有在线性空间中表示，或者可能在相似性得分上没有等效的权重。因此，研究人员建议使用机器学习模型来确定两个函数是否相似，并给出一组提取的特征作为输入。有几种方法可以通过利用贝叶斯网络、卷积神经网络、图匹配网络（GMN）、规则前馈神经网络或它们的组合来实现这种类型的相似性。在这些情况下，该模型用于输出一对函数之间的相似性得分。</p>
<p>为了找到类似的函数，这些方法需要搜索整个数据集，并将查询函数的特征与数据集中的每个条目进行比较，这不是一个可扩展的解决方案。出于这个原因，许多方法实现了索引策略，通过诸如基于树的数据结构、局部敏感散列（近似最近邻搜索）、bloom 过滤器、基于更简单数据的自定义预过滤器、聚类技术，甚至分布式搜索方法（如 map-reduce）来预过滤潜在的相似候选。</p>
<p><strong>第二类解决方案</strong>实现了间接比较技术。这些方法将输入特征映射为“浓缩”的低维表示，可以使用距离度量（如欧几里得距离或余弦距离）轻松地相互比较。这些解决方案允许高效的一对多比较。例如，如果需要将一个新函数与整个数据集进行比较，可以首先将存储库中的每个函数映射到其各自的低维表示（这是一次性操作），然后对新函数执行相同的操作，最后通过使用近似最近邻等有效技术比较这些表示。</p>
<h5 id="Fuzzy-hashes-and-embeddings"><a href="#Fuzzy-hashes-and-embeddings" class="headerlink" title="Fuzzy hashes and embeddings."></a>Fuzzy hashes and embeddings.</h5><p>低维表示的一个流行的例子是模糊散列。模糊哈希是由与传统加密哈希不同的算法产生的，因为它们被有意设计为将类似的输入值映射到类似的哈希。结论是输入原始字节的微小变化会显著影响生成的散列。然而，即使普通模糊哈希可能不适合函数相似性，一些方法（如 FunctionSimSearch）已经提出了更专门的哈希技术来比较两个函数。</p>
<p>另一种流行的低维表示形式依赖于 embeddings。这个术语在机器学习社区中很流行，指的是一个低维空间，在这个空间中，语义上相似的输入被映射到彼此接近的点，而不管输入在其原始表示中看起来有多么不同。机器学习模型的目标是学习如何产生 embeddings，使相似函数之间的相似性最大化，并使不同函数之间的相似性最小化。在文献中，我们可以识别出两种主要类型的 embeddings：一种试图总结每个函数的代码，另一种试图总结它们的图结构。</p>
<h5 id="Code-embeddings"><a href="#Code-embeddings" class="headerlink" title="Code embeddings"></a>Code embeddings</h5><p>许多研究者试图利用现有的自然语言处理（NLP）技术，通过将汇编代码作为文本处理来解决二值函数相似问题。这些解决方案处理 token 流（例如，指令、助记符、操作数、规范化指令），每个代码块输出一个 embedding，每个指令输出一个 embedding，或者两者都输出。<strong>第一类方法</strong>（如 Asm2Vec）基于 word2vec，这是自然语言处理领域的一种知名技术。尽管这些模型不是为跨架构嵌入生成而设计的，但它们可以同时在不同的指令集上进行训练，学习不同语言的语法（但不能跨语言映射语义)，或者它们可以应用于中间语言之上。<strong>第二种解决方</strong>案基于 seq2seq 编码器 - 解码器模型，该模型允许将不同架构的语义映射到相同的 embedding 空间，从而学习跨架构的相似性。<strong>第三种类型</strong>的模型建立在 BERT 之上，这是基于 NLP 中最先进的预训练模型。例如，OrderMatters 使用在四个任务上预训练的 BERT 模型来生成基本的块 embedding，而 Trex 使用分层转换器和掩码语言建模任务来学习近似的程序执行语义，然后将学习到的知识转移到识别语义相似的函数。</p>
<p>汇编代码 embedding 通常受到它们可以处理的不同指令的数量（所谓的词汇表外问题（OOV））以及可以作为模型输入提供的最大指令数量的影响。因此，某些方法计算指令级 embedding，基本块 embedding 或函数级 embedding。指令或基本块 embedding 有时利用其他算法（如最长公共子序列）来计算函数相似性，或者它们被用作更复杂模型的一部分。</p>
<h5 id="Graph-embeddings"><a href="#Graph-embeddings" class="headerlink" title="Graph embeddings"></a>Graph embeddings</h5><p>另一项研究建立在计算图嵌入的机器学习方法上。这些非常适合捕获基于函数控制流图的特性，本质上是跨架构的。这些嵌入可以通过自定义算法或更复杂的机器学习技术生成，例如图神经网络（GNN）。最近来自机器学习社区的一些方法提出了 GNN 的变体，例如图匹配网络（GMN）。这些变化能够在向量空间中产生可比较的嵌入，其特殊性在于这些嵌入对作为模型输入的两个图中的信息进行编码。</p>
<p>图嵌入方法还经常将每个基本块的信息编码到图的相应节点中，以增加表达性。例如，一些解决方案为每个节点计算一组属性，从而产生有属性控制流图（attributecontrolflow Graphs, ACFG），ACFG 可以手工设计，也可以以无监督的方式自动学习。其他作者利用前面讨论的一些技术利用其他嵌入计算层（例如，在基本块级别）。</p>
<h4 id="Function-Representations"><a href="#Function-Representations" class="headerlink" title="Function Representations"></a>Function Representations</h4><p>二进制函数本质上是与特定于体系结构的机器码和数据相对应的字节流。从这个原始输入开始，研究人员使用了许多方法来提取更高级的信息，这些信息可以用来判断两个函数是否来自相同的源代码。该列表按抽象级别的增加排序，包括以下类别。</p>
<h5 id="Raw-bytes"><a href="#Raw-bytes" class="headerlink" title="Raw bytes"></a>Raw bytes</h5><p>一些解决方案直接使用原始二进制信息作为相似性度量的起点。</p>
<h5 id="Assembly"><a href="#Assembly" class="headerlink" title="Assembly"></a>Assembly</h5><p>汇编指令是由反汇编器获得的，当可以根据指令大小或操作数以多种不同的方式对操作进行编码时，汇编指令是有用的。</p>
<h5 id="Normalized-assembly"><a href="#Normalized-assembly" class="headerlink" title="Normalized assembly"></a>Normalized assembly</h5><p>汇编代码通常对常量进行编码，导致操作数和操作数的潜在组合数量较多。使用归一化汇编指令抽象出部分可变性，减少词汇量，并将相同操作的所有可能变化聚合到单个表示中。</p>
<h5 id="Intermediate-representations"><a href="#Intermediate-representations" class="headerlink" title="Intermediate representations"></a>Intermediate representations</h5><p>有些方法通过将二进制表示提升到中间表示（IR），在更高的抽象级别上工作。IR 的使用带来了几个优点：它可以统一语义等价但句法上不同的指令的表示；它可能会抽象出不同架构的非相关工件；它允许应用程序分析技术来简化（和收敛）某些代码结构。</p>
<h5 id="Structure"><a href="#Structure" class="headerlink" title="Structure"></a>Structure</h5><p>许多方法试图捕捉给定函数的内部结构，或者函数在整个程序中扮演的角色。</p>
<h5 id="Data-flow-analysis"><a href="#Data-flow-analysis" class="headerlink" title="Data flow analysis"></a>Data flow analysis</h5><p>在程序集级别的算术表达式的实现可以采用不同的形式来实现相同的语义。</p>
<h5 id="Dynamic-analysis"><a href="#Dynamic-analysis" class="headerlink" title="Dynamic analysis"></a>Dynamic analysis</h5><p>一些方法依赖于动态分析。</p>
<h5 id="Symbolic-execution-and-analysis"><a href="#Symbolic-execution-and-analysis" class="headerlink" title="Symbolic execution and analysis"></a>Symbolic execution and analysis</h5><p>与具体的动态执行相反，一些方法依赖于符号执行来完全捕获分析下函数的行为，并在所有可能的路径下确定其输入与其输出之间的关系。</p>
<h3 id="Selected-Approaches"><a href="#Selected-Approaches" class="headerlink" title="Selected Approaches"></a>Selected Approaches</h3><p>本文的主要贡献之一是位许多关键方法提供实现参考，并在公开和全面的数据集上进行实验来予以比较。理想情况下，人们会评估尽可能多的方法，但显然，重新实现它们是不可行的。同样重要的是要明白，虽然有数百篇关于该主题的论文，但其中许多都是相同技术的小变化，而新颖解决方案的数量明显较少。</p>
<h4 id="Selection-Criteria"><a href="#Selection-Criteria" class="headerlink" title="Selection Criteria"></a>Selection Criteria</h4><h5 id="Scalability-and-real-world-applicability"><a href="#Scalability-and-real-world-applicability" class="headerlink" title="Scalability and real-world applicability"></a>Scalability and real-world applicability</h5><p>我们对有可能扩展到大型数据集的方法感兴趣，这些方法可以应用于现实世界的用例。因此，我们不评估那些固有的缓慢且只关注直接比较的方法，例如基于动态分析、符号执行或高复杂性图相关算法的方法。</p>
<h5 id="Focus-on-representative-approaches-and-not-on-specific-papers"><a href="#Focus-on-representative-approaches-and-not-on-specific-papers" class="headerlink" title="Focus on representative approaches and not on specific papers"></a>Focus on representative approaches and not on specific papers</h5><p>有许多研究工作提出了相同方法的小变化，例如，通过重用以前的技术，同时稍微改变使用的特征。这通常会导致相似的总体精度，这使得它们在我们的比较中不那么有趣。</p>
<h5 id="Cover-different-communities"><a href="#Cover-different-communities" class="headerlink" title="Cover different communities"></a>Cover different communities</h5><p>对二值函数相似度问题的研究贡献来自不同的研究团体和学术界和工业界。本文希望概括来自多个社区的代表性研究，同时还考虑了行业提出的方法。</p>
<h5 id="Prioritize-latest-trends"><a href="#Prioritize-latest-trends" class="headerlink" title="Prioritize latest trends"></a>Prioritize latest trends</h5><p>虽然这一研究领域的第一个贡献可以追溯到十多年前，但最近兴趣激增。本文综合考虑了各种类型的方法，在此基础上，优先考虑最新的研究。</p>
<h4 id="Selected-Approaches-1"><a href="#Selected-Approaches-1" class="headerlink" title="Selected Approaches"></a>Selected Approaches</h4><p>根据分析，确定了 30 种技术，如图 1 所示，然后我们从中选择了 10 种具有代表性的解决方案用于我们的研究。</p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325161030521.png" alt="image-20240325161030521" style="zoom: 33%;"></p>
<p>左图显示了根据各自研究小组聚类的方法。这些团体来自学术界和工业界——谷歌和腾讯在这一领域都非常活跃。边线代表其他的解决方案，每篇论文将其结果与之比较。例如，Gemini 和 Genius 之间的箭头表示作者将 Gemini 的结果与 Genius 先前获得的结果进行了比较（两者来自同一组）。图 1 的右侧部分在 Y 轴上显示发布的时间轴，在 X 轴上显示不同类型的输入数据。然后根据计算相似度的不同方法将这些方法聚类为三大类，即模糊哈希、图嵌入和代码嵌入。</p>
<p>这两个图片都使用标签（括号中）来识别社区（[S] 安全性，[PL] 编程语言，[ML] 机器学习，以及 [SE] 软件工程）。我们还使用 [Mono] 和 [Cross] 标签来表示所提出的方法是否分别关注单架构或跨架构场景。</p>
<p>即使图 1 中的图表并不全面，只显示了我们选择的论文，它也再次描述了几篇论文如何仅与之前有限的一组方法进行比较。我们还可以从这些图中提取出其他有趣的信息。首先，在中间框中分组的二进制区分工具都是为直接比较两个二进制文件而设计的（例如，它们使用调用图），并且它们都是单一架构的。其次，图表显示，不同的社区往往是相当封闭的，他们很少与其他领域的论文进行比较。这是推进函数相似度研究的明显局限性，我们希望本文能够促进不同领域之间的合作。最后，我们可以找出一些开创性的论文，如 Gemini 和 discoverRE，这些论文在其他研究中被重新实施和广泛测试。这些工作显然激励了其他研究人员提高技术水平。</p>
<p>右边的时间轴图显示了一个明显的趋势：解决方案的复杂性和机器学习的使用随着时间的推移而增长。我们使用这些信息和图中描述的关系来选择 10 个最先进的解决方案，这些解决方案是可伸缩的、具有代表性的和最新的。与此同时，我们试图最大化研究团体之间的差异。</p>
<h5 id="Bytes-fuzzy-hashing-Catalog1"><a href="#Bytes-fuzzy-hashing-Catalog1" class="headerlink" title="Bytes fuzzy hashing: Catalog1"></a>Bytes fuzzy hashing: Catalog1</h5><p>Catalog1 是一种基于 MinHash 局部敏感哈希的模糊哈希方法。该算法以函数字节作为输入并产生固定长度的签名，这是比较来自同一架构的功能的一种有前途的方法。</p>
<h5 id="CFG-fuzzy-hashing-FunctionSimSearch"><a href="#CFG-fuzzy-hashing-FunctionSimSearch" class="headerlink" title="CFG fuzzy hashing: FunctionSimSearch"></a>CFG fuzzy hashing: FunctionSimSearch</h5><p>FunctionSimSearch 使用 SimHash 算法计算模糊散列，该散列结合了从 CFG、助记符中提取的graphlet（即小连通、非同构、诱导子图）和来自汇编代码的直接值。</p>
<h5 id="Attributed-CFG-and-GNN-Gemini"><a href="#Attributed-CFG-and-GNN-Gemini" class="headerlink" title="Attributed CFG and GNN: Gemini"></a>Attributed CFG and GNN: Gemini</h5><p>Gemini 使用 GNN (Structure2vec) 从函数 ACFG（即具有基本块级别属性的控制流图）开始计算函数嵌入。这种方法标志着一个里程碑，因为它是第一个使用带有 Siamese 架构的 GNN 来学习函数相似性的人。</p>
<h5 id="Attributed-CFG-GNN-and-GMN-Li-et-al-2019"><a href="#Attributed-CFG-GNN-and-GMN-Li-et-al-2019" class="headerlink" title="Attributed CFG, GNN, and GMN: Li et al. 2019"></a>Attributed CFG, GNN, and GMN: Li et al. 2019</h5><p>一种新颖的图匹配模型来计算图对之间的相似性。作者探索了函数相似性作为实际用例之一。</p>
<h5 id="IR-data-flow-analysis-and-neural-network-Zeek"><a href="#IR-data-flow-analysis-and-neural-network-Zeek" class="headerlink" title="IR, data flow analysis and neural network: Zeek"></a>IR, data flow analysis and neural network: Zeek</h5><p>Zeek 在基本块级别对提升代码（VEX IR）执行数据流分析（切片），并计算链。然后，训练一个两层全连接神经网络来学习跨架构相似性任务。这种方法是结合中间表示、数据流分析和机器学习的高级建议。</p>
<h5 id="Assembly-code-embedding-Asm2Vec"><a href="#Assembly-code-embedding-Asm2Vec" class="headerlink" title="Assembly code embedding: Asm2Vec"></a>Assembly code embedding: Asm2Vec</h5><p>Asm2Vec NLP 模型源自 paragraph2vec 的 PV-DM 变体，这是原始 word2vec 模型的扩展。Asm2Vec 引入了更精细的指令级拆分和嵌入构造，以克服具有装配指令的词汇外 (OOV) 问题的局限性。这种方法是完全无监督的，并在单架构实验中取得了最先进的结果。</p>
<h5 id="Assembly-code-embedding-and-self-attentive-encoder-SAFE"><a href="#Assembly-code-embedding-and-self-attentive-encoder-SAFE" class="headerlink" title="Assembly code embedding and self-attentive encoder: SAFE"></a>Assembly code embedding and self-attentive encoder: SAFE</h5><p>SAFE 使用自我注意句子编码器来学习跨体系结构函数嵌入。这种方法代表了来自 seq2seq 模型的 NLP 编码器，并且与 Asm2Vec 相比，它是专门为学习跨架构相似性而设计的。</p>
<h5 id="Assembly-code-embedding-CFG-and-GNN-Massarelli-et-al-2019"><a href="#Assembly-code-embedding-CFG-and-GNN-Massarelli-et-al-2019" class="headerlink" title="Assembly code embedding, CFG and GNN: Massarelli et al., 2019"></a>Assembly code embedding, CFG and GNN: Massarelli et al., 2019</h5><p>Mamasarelli 等人使用了 Gemini 相同的 Structure2vec GNN，但它改变了块级特征，从手动设计的特征切换到无监督特征。它是 Gemini 的演变，结合了指令级嵌入、基本块编码器和 GNN 的优点。</p>
<h5 id="CodeCMR-BinaryAI"><a href="#CodeCMR-BinaryAI" class="headerlink" title="CodeCMR/BinaryAI"></a>CodeCMR/BinaryAI</h5><p>只关注以二进制格式处理函数的部分。该模型将中间表示与 NLP 编码器相结合以获得基本块嵌入和 GNN 以获得图嵌入。两个 LSTM 从函数中编码字符串和整数数据。函数嵌入是三个的串联，二进制模型是端到端训练的。</p>
<h5 id="Trex"><a href="#Trex" class="headerlink" title="Trex"></a>Trex</h5><p>Trex 是最近基于分层 Transformer 和微跟踪的工作。本文提出了一种提取函数轨迹的动态组件，这是学习函数语义的基础。作者在这些轨迹上预训练 ML 模型，并转移学习到的知识以匹配语义相似的函数。匹配阶段完全基于静态特征，而模拟生成微跟踪只需要在预训练期间。这种跨架构解决方案建立在 Transformer 之上，Transformer 是 NLP 中最先进的深度学习模型。</p>
<h3 id="Evaluation"><a href="#Evaluation" class="headerlink" title="Evaluation"></a>Evaluation</h3><h4 id="Implementation"><a href="#Implementation" class="headerlink" title="Implementation"></a>Implementation</h4><p>本文是为了在不同的方法之间进行相对公平的比较。基于此，作者以统一的方式完成了评估的各个阶段，包括二进制分析、特征提取和机器学习实现，创建一个共同点以对不同的方法进行有意义和公平的比较。</p>
<p>对于二进制分析部分，本文使用 IDA Pro；对于特征提取，则依赖于使用 IDA Pro api, Capstone 和 NetworkX 的一组 Python 脚本。本文在 Tensorflow 1.14 中实现了所有的神经网络模型，唯一的例外是 Trex，它是建立在 Fairseq 之上的，Fairseq 是 PyTorch 的序列建模工具包。最后，使用 Gensim 3.8 实现 Asm2Vec 并运行指令嵌入模型。</p>
<p>采用统一的实现来最小化计算差异，并引入代码优化。当代码不可以时，本文联系了对应作者，但得到的支持和答复有限。Zeek 和 Asm2Vec 已经完全重现，但 CodeCMR 由于模型复杂等还在测试。</p>
<h4 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h4><p>本文创建了两个数据集 Dataset-1 和 Dataset-2，旨在捕捉现实世界软甲你得复杂和可变，同时涵盖了二元函数相似性的不同挑战：多个编译器和版本、多个编译优化选项、多个架构、不同位数以及不同性质的软件。使用 Dataset-1  训练模型，使用两个数据集进行测试评估。</p>
<h5 id="Dataset-1"><a href="#Dataset-1" class="headerlink" title="Dataset-1"></a>Dataset-1</h5><p>禁用函数内联。</p>
<h5 id="Dataset-2"><a href="#Dataset-2" class="headerlink" title="Dataset-2"></a>Dataset-2</h5><h5 id="Dataset-availability"><a href="#Dataset-availability" class="headerlink" title="Dataset availability"></a>Dataset availability</h5><p>作者发布了包括编译脚本和补丁在内的完整数据集。</p>
<h4 id="Experimental-Settings"><a href="#Experimental-Settings" class="headerlink" title="Experimental Settings"></a>Experimental Settings</h4><p>本文确定了六个不同的任务来进行评估：</p>
<ol>
<li>XO：函数对具有不同的优化，但是使用相同的编译器，版本与架构均相同</li>
<li>XC：函数对使用不同的编译器、版本以及优化，但是架构和位数相同</li>
<li>XC + XB：函数对使用不同的编译器、版本、优化及位数，但是架构相同</li>
<li>XA：函数对使用不同的架构、位数，但是使用相同的编译器、版本及优化</li>
<li>XA + XO：函数对使用不同的架构、位数以及优化，但是编译器和版本相同</li>
<li>XM：函数对来自任意的架构、位数、编译器、版本以及优化</li>
</ol>
<p>前三个任务仅评估那些仅限于单一架构的用例的技术，包括功能相似性在恶意软件分析和协作逆向工程中的一些实际应用。第四个任务与使用始终相同的编译器和编译器选项交叉编译的固件图像的分析相关。第五个任务旨在支持 Dataset-2，该数据集仅使用一个编译器和编译器版本编译。最后，最后一个任务最具挑战性的，包括整个数据集的比较。在我们的评估中，我们还考虑了 XM 的三个子数据集：XM-S、XM-M 和 XM-L，其中包括小尺寸函数（少于 20 个基本块）、中等（在 20 到 100 之间）和大函数（超过 100 个块）。</p>
<h4 id="Fuzzy-hashing-Comparison"><a href="#Fuzzy-hashing-Comparison" class="headerlink" title="Fuzzy-hashing Comparison"></a>Fuzzy-hashing Comparison</h4><p>Catalog1 使用原始字节作为输入特征和不同的签名大小（即哈希函数的数量）：本文展示了两个变体的结果，大小分别为 16 和 128。FunctionSimSearch （FSS）使用 graphlets（G）、mnemonics（M）和 directions（I）的组合：通过增量启用不同类型的输入特征（包括加权线性组合）来进行不同的测试。</p>
<p>由于模糊哈希方法不受训练阶段的影响，因此我们使用它们来对每个编译变量如何影响二进制函数的比较进行有针对性的评估。因此，对于这些方法，我们首先执行多个实验，其中我们改变一个变量（即，编译器，版本，优化选项，体系结构和位），而保持其余的不变。表 1 中的结果清楚地表明，当一次只考虑一个自由变量时，即使是模糊哈希这样的简单方法也是有效的:“原始”字节被证实是相同架构比较的好特性，而 graphlet 在跨架构比较中是有效的。对于 Catalog1，签名大小越大，性能越好，但它们受到实现中包含的散列函数总数的限制。</p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325205840655.png" alt="image-20240325205840655" style="zoom:50%;"></p>
<p>使用前面提到的六个任务对这两种方法进行评估。表 2 和表 4 显示了在两个 Dataset 上的结果：同时处理多个自由变量是个较难的问题，简单的方法无法奏效。在 XC 任务中（表 2），Catalog1 和 FSS 具有相同的 AUC。对于 FSS，仅 graphlets （G）配置在 XC 和 XO 以外的所有任务中都是最好的，其中使用带有助记符（G+M）的 graphlet 具有更高的 AUC。此外，FSS 在更大的函数上工作得更好，可能是由于可以提取的不同 graphlet 的数量更高。最后，在 XA 任务中，当使用助记符和即时等附加特征时，FSS 准确度会降低，但是，三个特征的加权线性组合不会产生比其他基本配置更好的结果。Catalog1 是这两种方法中最快的，而由于特征提取阶段较长，FSS 的速度大约慢 3 倍。</p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325210238734.png" alt="image-20240325210238734" style="zoom: 33%;"></p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325210846038.png" alt="image-20240325210846038" style="zoom:33%;"></p>
<h4 id="Machine-learning-Models-Comparison"><a href="#Machine-learning-Models-Comparison" class="headerlink" title="Machine-learning Models Comparison"></a>Machine-learning Models Comparison</h4><p>本文通过使用从 Dataset-1 中提取的公共训练数据集评估所选择的所有方法，并使用与 XM 任务相似的标准来创建正负样本。注意到在最通用数据上进行训练可以或者接近每个任务最佳的总体性能。</p>
<p>比较机器学习模型，尤其是深度神经网络，是一项具有挑战性的任务，因为几个变量可能会影响最终结果，包括模型实现和配置（例如，层数或循环神经网络的类型）、不同的超参数（例如学习率和批量大小）、损失函数、优化器和训练时期的数量。本文中，所有的模型都使用相同随机生成的数据进行训练。作者进行了大量实验来评估不同的特征集、模型配置、超参数以及损失函数等。</p>
<p>表 3 和表 4 显示了测试模型的结果及其在两个数据集上的相应变体。表 8 包括有关模型及其训练的一些通用信息，例如参数数量、批量大小、epoch 数和每个 epoch 的训练时间。</p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325211258114.png" alt="image-20240325211258114" style="zoom: 33%;"></p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325211325777.png" alt="image-20240325211325777" style="zoom:33%;"></p>
<p>结果表明，在产生函数向量表示（即 embedding）的模型中，GNN 在所有指标和所有任务中都达到了最佳值。注意到大多数机器学习模型在 AUC 上的表现非常相似，但在排名指标（MRR10 和 recall@1）上却有所不同，如图 2 所示。然后，对于其他 embedding 模型，SAFE 提供的 AUC 优于具有无监督特征的 GNN，并且在一个特定配置下的 AUC 略好于 Gemini。对于执行直接比较的方法，GMN 是所有任务中表现最好的模型，而 Zeek 的 AUC 略低（除了大型函数），但 MRR10 和 recall@1 要低得多。</p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325211600064.png" alt="image-20240325211600064" style="zoom:33%;"></p>
<h5 id="Comparing-Trex"><a href="#Comparing-Trex" class="headerlink" title="Comparing Trex"></a>Comparing Trex</h5><p>在 XO 任务中，Trex 的 AUC 和与 Asm2Vec 相似的 MRR10 和 recall@1，以及其他 word2vec 变体，略低于 GNN 和 GMN 之一。与 Asm2Vec 不同，Trex 在 XA 和 XA+XO 任务中也保留了相同的性能，这表明了 Transformer 在（跨语言）跨架构设置中的强大功能。Trex 在 XO 任务 (0.94 vs. 0.90) 和 XA+XO 任务中提高了 SAFE 性能 (0.94 vs. 0.91)。在 GPU 上运行的 Trex 的推理比多进程 Asm2Vec 实现（100 个函数的 3.92 秒 vs. 8.51 秒）更快，但它比运行在 CPU 上的 SAFE 慢（100 个函数的 3.92 秒 vs. 1.46）。</p>
<h5 id="Comparing-different-GNNs"><a href="#Comparing-different-GNNs" class="headerlink" title="Comparing different GNNs"></a>Comparing different GNNs</h5><p>都使用具有不同消息传递和聚合层的变体的 GNN。使用表 3 和表 4 中第三行和第四个行块的结果，我们使用基本块特征（操作码的单词包（BoW））和无特征来比较这两种变体。在所有任务中，Gemini 使用的 GNN (s2v) 提供了显着改进。然而，两种变体的执行时间仍然相似（在不使用特征时为 1.48 秒 vs. 1.40 秒）。</p>
<h5 id="Comparing-different-feature-set-in-GNN-s2v"><a href="#Comparing-different-feature-set-in-GNN-s2v" class="headerlink" title="Comparing different feature set in GNN (s2v)"></a>Comparing different feature set in GNN (s2v)</h5><p>Gemini 使用称为 Structure2vec (s2v) 的 GNN 模型，具有手动设计的特征。目标是了解这些特征对于根本不具有特征向量或使用另一组特征（例如操作码的单词包（BoW）的重要性。表 3 和表 4 中的结果表明，人工设计的特征仅在 XA 任务中的小函数和大函数上表现更好，并且操作码的 BoW 在所有不同的指标中都表现相似，甚至对不同的 K 值具有更好的召回率，如图 2 所示。此外，由于 Gemini 中的特征提取阶段较长，执行时间不同（1.66s vs. 7.18s）。这意味着更复杂和更难提取特征并不一定优于更基本的表示。200 个操作码的 BoW 具有 Gemini 特征数量的 20 倍，这导致 GNN 的节点神经网络的输入矩阵更大。我们还测试了 1024 个操作码的 BoW，但结果并没有显着提高，这意味着这些附加特征对函数的表示没有显着贡献。</p>
<p>归一化的汇编上的指令 embedding 并不比操作码或手动设计的词袋具有更高的 AUC 和 MRR10，recall@1 也较低，训练时间却急剧增加。</p>
<h5 id="Modelling-functions-using-a-textual-encoder"><a href="#Modelling-functions-using-a-textual-encoder" class="headerlink" title="Modelling functions using a textual encoder"></a>Modelling functions using a textual encoder</h5><p>SAFE 使用基于指令嵌入的句子编码器，AUC 优于具有无监督特征的 GNN (s2v)。与 Gemini 相比，AUC 相似，但 MRR10 和 recall@1 较低。SAFE 在小函数上效果更好，当最大指令长度从 150 增加到 250 时，结果确实有所提高（表 3）。然而，SAFE 需要面对词汇外 (OOV) 词的挑战。InnerEye 或 Mirror 等其他方法应用不同的归一化汇编来缓解这个问题。为了说明这一挑战，我们测量了 OOV 指令在 SAFE 中的影响，我们观察到 x86-64 是 OOV 问题影响最大的架构（不到 30% 的函数没有 OOV 词），这可能是由于它的 CISC 指令集，然后是 MIPS，最后是 ARM，有超过 40% 的函数没有单个 OOV 词。</p>
<h5 id="Asm2Vec-and-other-paragraph2vec-models"><a href="#Asm2Vec-and-other-paragraph2vec-models" class="headerlink" title="Asm2Vec and other paragraph2vec models"></a>Asm2Vec and other paragraph2vec models</h5><p>表 3 和表 4 显示了 Asm2Vec 与 paragraph2vec 的 PV-DM 和 PV-DBOW 变体的比较结果。所有三个模型的性能相似，与 GNN 相比，使用特定的单架构方法并没有带来任何优势。注意到结果受到多种因素的影响，包括指令词汇表的大小、随机游走的数量以及几个实现细节。在训练期间，选择了最小频率为 5 的 1M 个标记（在 1.9M 中），其中大多数是数值偏移或十六进制地址。降低阈值确实改善了结果，但也增加了词汇量和训练时间。在推理时，没有更改词汇表，尽管这些无监督方法可以从新的推理词汇表中中受益，而不会使结果无效。在测试中，所有三个模型都共享相同的词汇表。还注意到，所有三种变体在只有一个变量自由的情况下都实现了高 AUC，例如表 4 中的 XO 任务，但当同时考虑多个编译变量时，AUC 会下降，例如表 3 中的 XC 任务，其中编译器、它的版本和优化更改。</p>
<h5 id="Comparing-efficiency"><a href="#Comparing-efficiency" class="headerlink" title="Comparing efficiency"></a>Comparing efficiency</h5><p>由于模型训练主要是一次性的努力，故而重点专注模型的推理时间效率。SAFE 在处理 100 个函数的机器学习模型中似乎最快。GMN 和 GNN 具有相似的运行时间和最低的运行时间，但是 GMN 仅在输入中处理一对函数。具有 Gemini 特征的 GNN (s2v) 比具有操作码特征的版本慢 4 倍：原因是更长的特征提取时间。Zeek 推理时间也受到长特征提取和处理时间的影响，在方法中是最慢的。由于额外的模型复杂性给出的推理时间较长，具有无监督特征的 GNN (s2v) 在 RNN 变体中速度较慢。同样，由于 NLP 模型的复杂性，Trex 受到较长的推理时间的影响。最后，Asm2Vec 是最慢的，因为它需要 10 个 epoch 的推理来提取新的函数嵌入。有趣的是，由于特定的指令嵌入构造，Asm2Vec 比其他 paragraph2vec 模型慢。</p>
<h5 id="CodeCMR-BinaryAI-evaluation"><a href="#CodeCMR-BinaryAI-evaluation" class="headerlink" title="CodeCMR/BinaryAI evaluation"></a>CodeCMR/BinaryAI evaluation</h5><p>如表 5 所示。使用 IDA 微码指令的 BoW 的 GNN 模型比使用操作码的 BoW 的 GNN 模型具有更高的 AUC，但第二个模型对于大K值具有更高的召回率（图 3）。一般来说，BinaryAI/CodeCMR 模型的所有指标都高于我们测试的其他模型。如果这些结果得到社区独立研究的验证，这可能是一个非常有前途的研究方向。</p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325222231594.png" alt="image-20240325222231594" style="zoom:33%;"></p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325222603853.png" alt="image-20240325222603853" style="zoom:33%;"></p>
<h5 id="Notes-about-Kim-et-al"><a href="#Notes-about-Kim-et-al" class="headerlink" title="Notes about Kim et al"></a>Notes about Kim et al</h5><p>在 Kim 等人在 Arxiv 上发表的论文中，作者提出了一种可解释的模型，并表明手动特征工程可以获得与“最先进的模型”相当的结果，即 Vulseeker。他们的评估一次只考虑一个变量变化（例如，只有编译器更改，而架构和优化级别是固定的）。与我们的六个评估任务相比，这是一个简化的设置，如表 1 所示，即使是简单的模糊散列方法也是有效的。但是，该论文缺乏对最先进技术的任何有意义的评估。</p>
<h4 id="Vulnerability-Discovery-Use-Case"><a href="#Vulnerability-Discovery-Use-Case" class="headerlink" title="Vulnerability Discovery Use Case"></a>Vulnerability Discovery Use Case</h4><p>本文在漏洞发现任务上测试了所有模型。在评估漏洞发现结果时，仅将特定固件映像的易受攻击函数用作查询。结果如表 7 所示：使用 MRR10 作为比较指标来评估每个模型如何为每个查询函数对目标脆弱函数进行排名。具有操作码特征的 GMN 模型是性能最好的模型，但它需要分析每对函数，从而限制了方法的可扩展性。Trex 和 Li 等人的 GNN 变体提供了第二好的结果。</p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325222630285.png" alt="image-20240325222630285" style="zoom:33%;"></p>
<p>然而与 Netgear R7000 相比，具有自定义权重的 FSS 型号在 x64 比较中具有最高的 MRR10。本文使用了代码中附带的权重，这些权重已经针对 OpenSSL 的比较进行了优化。这证明 FSS 实现的优化过程具有实际用例，但它不能扩展到其他配置。表 7 还显示了不同体系结构之间的比较，特别是 Netgear 的 ARM32 列和 TP-Link 的 MIPS32 列显示了相同体系结构的比较。Netgear R7000 固件为 ARM 32 位编译，而 TP-Link Deco-M4 为 MIPS 32 位编译：这显示了 Asm2Vec 在相应列中具有高 MRR10 值的原因。最后，表 6 包含了 Netgear R7000 图像的脆弱函数的实际排名结果，可以看出在实践中较高的 MRR10 值可能隐藏着较低的排名。</p>
<p><img src="https://github.com/lxmliu2002/images/raw/main/post/20240325/image-20240325222914629.png" alt="image-20240325222914629" style="zoom:33%;"></p>
<h3 id="Discussion"><a href="#Discussion" class="headerlink" title="Discussion"></a>Discussion</h3><p>结果表明，一个机器学习模型，Li 等人的 GNN 在六个评估任务中优于所有其他变体，实现了类似于不太可扩展的 GMN 版本的性能。其他基于 embedding 的模型显示较低但相似的准确度。Zeek 是一种直接比较方法，在大函数上具有更高的 AUC。Asm2Vec 的表现并不比其他模型好，当多个编译变量同时变化时，模糊散列方法无效。</p>
<h4 id="Which-are-the-main-contributions-of-the-novel-machinelearning-solutions-compared-to-simpler-fuzzy-hashing-approaches"><a href="#Which-are-the-main-contributions-of-the-novel-machinelearning-solutions-compared-to-simpler-fuzzy-hashing-approaches" class="headerlink" title="Which are the main contributions of the novel machinelearning solutions compared to simpler fuzzy hashing approaches?"></a>Which are the main contributions of the novel machinelearning solutions compared to simpler fuzzy hashing approaches?</h4><p>深度学习模型提供了一种学习函数表示（即 embedding）的有效方法，强制在不同类型的函数之间进行空间分离。与模糊哈希方法不同，机器学习模型即使在多个编译变量同时发生变化时也能实现高精度，并且它们受益于构建在编译选项定义的可靠基础真理之上的大型训练数据集的优势。</p>
<h4 id="Which-is-the-role-of-different-sets-of-features"><a href="#Which-is-the-role-of-different-sets-of-features" class="headerlink" title="Which is the role of different sets of features?"></a>Which is the role of different sets of features?</h4><p>机器学习模型类型的选择，特别是 GNN 和损失函数的选择与输入中的特征同样重要。使用基本块特征（例如，ACFG）可以提供更好的结果，但是在精心手工设计的特征和更简单的特征（例如基本块操作码的单词包）之间存在很小的区别。指令内 embedding 并没有提高 GNN 模型的性能，但是本文认为需要进行广泛的测试来评估其他可能的组合。Zeek 展示了数据流信息如何提高结果，特别是对于大函数。最后，由于缺乏训练阶段，模糊哈希方法对特征类型更敏感。</p>
<h4 id="Do-different-approaches-work-better-at-different-tasks-In-particular-is-the-cross-architecture-comparison-more-difficult-than-working-with-a-single-architecture"><a href="#Do-different-approaches-work-better-at-different-tasks-In-particular-is-the-cross-architecture-comparison-more-difficult-than-working-with-a-single-architecture" class="headerlink" title="Do different approaches work better at different tasks? In particular, is the cross-architecture comparison more difficult than working with a single architecture?"></a>Do different approaches work better at different tasks? In particular, is the cross-architecture comparison more difficult than working with a single architecture?</h4><p>本文的评估表明，大多数机器学习模型在所有评估任务上的表现非常相似，无论是在同一架构还是跨架构中。此外，没有必要在特定任务上训练它们，因为使用最通用的任务数据（XM）可以实现整体接近每个任务最佳的性能。模糊散列方法并非如此。然而，并非所有方法都可以在跨架构比较中使用。</p>
<h4 id="Is-there-any-specific-line-of-research-that-looks-more-promising-as-a-future-direction-for-designing-new-techniques"><a href="#Is-there-any-specific-line-of-research-that-looks-more-promising-as-a-future-direction-for-designing-new-techniques" class="headerlink" title="Is there any specific line of research that looks more promising as a future direction for designing new techniques?"></a>Is there any specific line of research that looks more promising as a future direction for designing new techniques?</h4><p>结果表明，深度学习模型对于不同的函数相似度任务具有可扩展性和精度要求，特别是由于能够学习适合于多个任务的函数表示。虽然 GNN 模型提供了最好的结果，但还有几十种不同的变体需要测试。此外，GNN 与汇编指令编码器的结合是另一个有前途的方向。以前的许多工作都专注于他们选择不同的特征和特征抽象级别的努力，但最近的机器学习模型仅使用归一化汇编代码或中间表示，利用表示学习的力量。还必须研究组合中间表示和数据流信息的效果。此外，我们观察到特征和机器学习模型的选择并不是影响方法性能的唯一方面。过去几乎没有讨论其中一些互补方面。</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>本文进行了第一次系统研究，涵盖了处理二元函数相似性的五年多的研究工作。确定了研究领域的一些挑战，以及它们如何做出有意义的比较变得困难，如果不是完全不可能的话。我们的工作旨在弥合这一差距并帮助社区在该领域获得清晰度。希望通过发布我们所有的实现、数据集和原始结果，社区将有一个参考点来开始构建新方法，并将鼓励他们与一个共同的框架进行评估，以更好地辨别哪些新方面实际上正在提高技术水平，哪些方面似乎这样做。</p>
<h3 id="Acknowledgements"><a href="#Acknowledgements" class="headerlink" title="Acknowledgements"></a>Acknowledgements</h3><h2 id="references"><a href="#references" class="headerlink" title="references"></a>references</h2><p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=e9bab7GpwnI">https://www.youtube.com/watch?v=e9bab7GpwnI</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_33976344/article/details/130987005">https://blog.csdn.net/qq_33976344/article/details/130987005</a></p>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/527154047?utm_id=0">https://zhuanlan.zhihu.com/p/527154047</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">Xiuming Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2024/03/25/PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem/">http://example.com/2024/03/25/PaperReading_How_Machine_Learning_Is_Solving_the_Binary_Function_Similarity_Problem/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">lxmliu2002's blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Binary-Code-Search/">Binary-Code-Search</a><a class="post-meta__tags" href="/tags/Vulnerability-Search/">Vulnerability-Search</a></div><div class="post_share"><div class="social-share" data-image="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/07/15/%E8%81%94%E9%82%A6%E5%AD%A6%E4%B9%A0_d2/" title="联邦学习_d2"><img class="cover" src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-secret_flow.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">联邦学习_d2</div></div></a></div><div class="next-post pull-right"><a href="/2024/03/24/PaperReading_jTrans/" title="PaperReading_jTrans"><img class="cover" src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">PaperReading_jTrans</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/03/22/PaperReading_Asm2Vec/" title="PaperReading_Asm2Vec"><img class="cover" src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-22</div><div class="title">PaperReading_Asm2Vec</div></div></a></div><div><a href="/2024/03/23/PaperReading_SANN/" title="PaperReading_SANN"><img class="cover" src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-23</div><div class="title">PaperReading_SANN</div></div></a></div><div><a href="/2024/03/24/PaperReading_jTrans/" title="PaperReading_jTrans"><img class="cover" src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-24</div><div class="title">PaperReading_jTrans</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://github.com/lxmliu2002/images/raw/main/lxmliu2002.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Xiuming Liu</div><div class="author-info__description">Stay hungry, stay foolish.</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">16</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lxmliu2002"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lxmliu2002" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:lxmliu2002@gamil.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#How-Machine-Learning-Is-Solving-the-Binary-Function-Similarity-Problem"><span class="toc-number">1.</span> <span class="toc-text">How Machine Learning Is Solving the Binary Function Similarity Problem</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%9A%E8%AF%BB"><span class="toc-number">1.1.</span> <span class="toc-text">通读</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Abstract"><span class="toc-number">1.1.1.</span> <span class="toc-text">Abstract</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Introduction"><span class="toc-number">1.1.2.</span> <span class="toc-text">Introduction</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Challenges"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">Challenges</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Contributions"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">Contributions</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#The-Binary-Function-Similarity-Problem"><span class="toc-number">1.1.3.</span> <span class="toc-text">The Binary Function Similarity Problem</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Measuring-Function-Similarity"><span class="toc-number">1.1.3.1.</span> <span class="toc-text">Measuring Function Similarity</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Direct-vs-indirect-comparison"><span class="toc-number">1.1.3.1.1.</span> <span class="toc-text">Direct vs. indirect comparison</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Fuzzy-hashes-and-embeddings"><span class="toc-number">1.1.3.1.2.</span> <span class="toc-text">Fuzzy hashes and embeddings.</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Code-embeddings"><span class="toc-number">1.1.3.1.3.</span> <span class="toc-text">Code embeddings</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Graph-embeddings"><span class="toc-number">1.1.3.1.4.</span> <span class="toc-text">Graph embeddings</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Function-Representations"><span class="toc-number">1.1.3.2.</span> <span class="toc-text">Function Representations</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Raw-bytes"><span class="toc-number">1.1.3.2.1.</span> <span class="toc-text">Raw bytes</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Assembly"><span class="toc-number">1.1.3.2.2.</span> <span class="toc-text">Assembly</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Normalized-assembly"><span class="toc-number">1.1.3.2.3.</span> <span class="toc-text">Normalized assembly</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Intermediate-representations"><span class="toc-number">1.1.3.2.4.</span> <span class="toc-text">Intermediate representations</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Structure"><span class="toc-number">1.1.3.2.5.</span> <span class="toc-text">Structure</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Data-flow-analysis"><span class="toc-number">1.1.3.2.6.</span> <span class="toc-text">Data flow analysis</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Dynamic-analysis"><span class="toc-number">1.1.3.2.7.</span> <span class="toc-text">Dynamic analysis</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Symbolic-execution-and-analysis"><span class="toc-number">1.1.3.2.8.</span> <span class="toc-text">Symbolic execution and analysis</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Selected-Approaches"><span class="toc-number">1.1.4.</span> <span class="toc-text">Selected Approaches</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Selection-Criteria"><span class="toc-number">1.1.4.1.</span> <span class="toc-text">Selection Criteria</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Scalability-and-real-world-applicability"><span class="toc-number">1.1.4.1.1.</span> <span class="toc-text">Scalability and real-world applicability</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Focus-on-representative-approaches-and-not-on-specific-papers"><span class="toc-number">1.1.4.1.2.</span> <span class="toc-text">Focus on representative approaches and not on specific papers</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Cover-different-communities"><span class="toc-number">1.1.4.1.3.</span> <span class="toc-text">Cover different communities</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Prioritize-latest-trends"><span class="toc-number">1.1.4.1.4.</span> <span class="toc-text">Prioritize latest trends</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Selected-Approaches-1"><span class="toc-number">1.1.4.2.</span> <span class="toc-text">Selected Approaches</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Bytes-fuzzy-hashing-Catalog1"><span class="toc-number">1.1.4.2.1.</span> <span class="toc-text">Bytes fuzzy hashing: Catalog1</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#CFG-fuzzy-hashing-FunctionSimSearch"><span class="toc-number">1.1.4.2.2.</span> <span class="toc-text">CFG fuzzy hashing: FunctionSimSearch</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Attributed-CFG-and-GNN-Gemini"><span class="toc-number">1.1.4.2.3.</span> <span class="toc-text">Attributed CFG and GNN: Gemini</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Attributed-CFG-GNN-and-GMN-Li-et-al-2019"><span class="toc-number">1.1.4.2.4.</span> <span class="toc-text">Attributed CFG, GNN, and GMN: Li et al. 2019</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#IR-data-flow-analysis-and-neural-network-Zeek"><span class="toc-number">1.1.4.2.5.</span> <span class="toc-text">IR, data flow analysis and neural network: Zeek</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Assembly-code-embedding-Asm2Vec"><span class="toc-number">1.1.4.2.6.</span> <span class="toc-text">Assembly code embedding: Asm2Vec</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Assembly-code-embedding-and-self-attentive-encoder-SAFE"><span class="toc-number">1.1.4.2.7.</span> <span class="toc-text">Assembly code embedding and self-attentive encoder: SAFE</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Assembly-code-embedding-CFG-and-GNN-Massarelli-et-al-2019"><span class="toc-number">1.1.4.2.8.</span> <span class="toc-text">Assembly code embedding, CFG and GNN: Massarelli et al., 2019</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#CodeCMR-BinaryAI"><span class="toc-number">1.1.4.2.9.</span> <span class="toc-text">CodeCMR&#x2F;BinaryAI</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Trex"><span class="toc-number">1.1.4.2.10.</span> <span class="toc-text">Trex</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Evaluation"><span class="toc-number">1.1.5.</span> <span class="toc-text">Evaluation</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Implementation"><span class="toc-number">1.1.5.1.</span> <span class="toc-text">Implementation</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Dataset"><span class="toc-number">1.1.5.2.</span> <span class="toc-text">Dataset</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Dataset-1"><span class="toc-number">1.1.5.2.1.</span> <span class="toc-text">Dataset-1</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Dataset-2"><span class="toc-number">1.1.5.2.2.</span> <span class="toc-text">Dataset-2</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Dataset-availability"><span class="toc-number">1.1.5.2.3.</span> <span class="toc-text">Dataset availability</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Experimental-Settings"><span class="toc-number">1.1.5.3.</span> <span class="toc-text">Experimental Settings</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Fuzzy-hashing-Comparison"><span class="toc-number">1.1.5.4.</span> <span class="toc-text">Fuzzy-hashing Comparison</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Machine-learning-Models-Comparison"><span class="toc-number">1.1.5.5.</span> <span class="toc-text">Machine-learning Models Comparison</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Comparing-Trex"><span class="toc-number">1.1.5.5.1.</span> <span class="toc-text">Comparing Trex</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Comparing-different-GNNs"><span class="toc-number">1.1.5.5.2.</span> <span class="toc-text">Comparing different GNNs</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Comparing-different-feature-set-in-GNN-s2v"><span class="toc-number">1.1.5.5.3.</span> <span class="toc-text">Comparing different feature set in GNN (s2v)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Modelling-functions-using-a-textual-encoder"><span class="toc-number">1.1.5.5.4.</span> <span class="toc-text">Modelling functions using a textual encoder</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Asm2Vec-and-other-paragraph2vec-models"><span class="toc-number">1.1.5.5.5.</span> <span class="toc-text">Asm2Vec and other paragraph2vec models</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Comparing-efficiency"><span class="toc-number">1.1.5.5.6.</span> <span class="toc-text">Comparing efficiency</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#CodeCMR-BinaryAI-evaluation"><span class="toc-number">1.1.5.5.7.</span> <span class="toc-text">CodeCMR&#x2F;BinaryAI evaluation</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Notes-about-Kim-et-al"><span class="toc-number">1.1.5.5.8.</span> <span class="toc-text">Notes about Kim et al</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Vulnerability-Discovery-Use-Case"><span class="toc-number">1.1.5.6.</span> <span class="toc-text">Vulnerability Discovery Use Case</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Discussion"><span class="toc-number">1.1.6.</span> <span class="toc-text">Discussion</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Which-are-the-main-contributions-of-the-novel-machinelearning-solutions-compared-to-simpler-fuzzy-hashing-approaches"><span class="toc-number">1.1.6.1.</span> <span class="toc-text">Which are the main contributions of the novel machinelearning solutions compared to simpler fuzzy hashing approaches?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Which-is-the-role-of-different-sets-of-features"><span class="toc-number">1.1.6.2.</span> <span class="toc-text">Which is the role of different sets of features?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Do-different-approaches-work-better-at-different-tasks-In-particular-is-the-cross-architecture-comparison-more-difficult-than-working-with-a-single-architecture"><span class="toc-number">1.1.6.3.</span> <span class="toc-text">Do different approaches work better at different tasks? In particular, is the cross-architecture comparison more difficult than working with a single architecture?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Is-there-any-specific-line-of-research-that-looks-more-promising-as-a-future-direction-for-designing-new-techniques"><span class="toc-number">1.1.6.4.</span> <span class="toc-text">Is there any specific line of research that looks more promising as a future direction for designing new techniques?</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Conclusion"><span class="toc-number">1.1.7.</span> <span class="toc-text">Conclusion</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Acknowledgements"><span class="toc-number">1.1.8.</span> <span class="toc-text">Acknowledgements</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#references"><span class="toc-number">1.2.</span> <span class="toc-text">references</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/07/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_d1/" title="数据分析_d1"><img src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-secret_flow.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据分析_d1"/></a><div class="content"><a class="title" href="/2024/07/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_d1/" title="数据分析_d1">数据分析_d1</a><time datetime="2024-07-22T16:00:00.000Z" title="发表于 2024-07-23 00:00:00">2024-07-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_d2/" title="数据分析_d2"><img src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-secret_flow.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据分析_d2"/></a><div class="content"><a class="title" href="/2024/07/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_d2/" title="数据分析_d2">数据分析_d2</a><time datetime="2024-07-22T16:00:00.000Z" title="发表于 2024-07-23 00:00:00">2024-07-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_d3/" title="数据分析_d3"><img src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-secret_flow.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据分析_d3"/></a><div class="content"><a class="title" href="/2024/07/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_d3/" title="数据分析_d3">数据分析_d3</a><time datetime="2024-07-22T16:00:00.000Z" title="发表于 2024-07-23 00:00:00">2024-07-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_d4/" title="数据分析_d4"><img src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-secret_flow.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="数据分析_d4"/></a><div class="content"><a class="title" href="/2024/07/23/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90_d4/" title="数据分析_d4">数据分析_d4</a><time datetime="2024-07-22T16:00:00.000Z" title="发表于 2024-07-23 00:00:00">2024-07-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/07/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_d1/" title="机器学习_d1"><img src="https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-secret_flow.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="机器学习_d1"/></a><div class="content"><a class="title" href="/2024/07/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0_d1/" title="机器学习_d1">机器学习_d1</a><time datetime="2024-07-22T16:00:00.000Z" title="发表于 2024-07-23 00:00:00">2024-07-23</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://github.com/lxmliu2002/images/raw/main/homepage/home-bg-03.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2024 By Xiuming Liu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="/js/tw_cn.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdn.jsdelivr.net/npm/pangu@4.0.7/dist/browser/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (false){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/dist/canvas-fluttering-ribbon.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=4.13.0"></script></div></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_clock_anzhiyu_injector_config(){
    var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
    var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img class="entered loading" id="card-clock-loading" src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading"/></div></div></div></div></div>';
    console.log('已挂载butterfly_clock_anzhiyu')
    if(parent_div_git) {
      parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  }
  var elist = 'null'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var qweather_key = 'b16a1fa0e63c46a4b8f28abfb06ae3fe';
  var gaud_map_key = 'e2b04289e870b005374ee030148d64fd&s=rsv3';
  var baidu_ak_key = 'undefined';
  var flag = 0;
  var clock_rectangle = '112.982279,28.19409';
  var clock_default_rectangle_enable = 'false';

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_clock_anzhiyu_injector_config();
  }
  else if (epage === cpage){
    butterfly_clock_anzhiyu_injector_config();
  }
  </script><script src="https://widget.qweather.net/simple/static/js/he-simple-common.js?v=2.0"></script><script data-pjax src="https://cdn.cbd.int/hexo-butterfly-clock-anzhiyu/lib/clock.min.js"></script><!-- hexo injector body_end end --></body></html>